<div align="center">

# âœˆï¸ Turbofan Engine Predictive Maintenance AI

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red?logo=streamlit&logoColor=white)](https://streamlit.io/)
[![NASA Dataset](https://img.shields.io/badge/Dataset-NASA%20C--MAPSS-blue)](https://data.nasa.gov/dataset/cmapss-jet-engine-simulated-data)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**A deep learning system for predicting the Remaining Useful Life (RUL) of turbofan jet engines using LSTM networks, with a live interactive Streamlit dashboard.**

[Overview](#-overview) â€¢ [Dataset](#-dataset) â€¢ [Model](#-model-architecture) â€¢ [Dashboard](#-live-dashboard) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Results](#-results) â€¢ [Team](#-team)

</div>

---

## ğŸ” Overview

Unscheduled maintenance in the aerospace and heavy machinery industries is one of the costliest operational challenges. A single unexpected engine failure can ground an aircraft, delay hundreds of passengers, and cost millions of dollars.

This project addresses that challenge head-on by building a **Prognostics and Health Management (PHM)** system that:

- ğŸ“Š **Ingests** raw time-series sensor data from turbofan engines
- ğŸ§¹ **Engineers** meaningful features and removes noisy/constant sensors
- ğŸ¤– **Trains** a deep LSTM network to predict how many cycles remain before failure
- ğŸ“ˆ **Visualises** predictions and sensor trends on a live Streamlit dashboard

> *"Predict failure before it happens â€” not after."*

---

## ğŸ“‚ Project Structure

```
Turbofan-engine-predictive-maintenance-ai/
â”œâ”€â”€ app.py                      # Streamlit dashboard
â”œâ”€â”€ nasa_rul_model.h5           # Pre-trained LSTM model
â”œâ”€â”€ train_FD001.txt             # Training set (FD001 subset)
â”œâ”€â”€ test_FD001.txt              # Test set (FD001 subset)
â”œâ”€â”€ RUL_FD001.txt               # Ground-truth RUL values for test set
â”œâ”€â”€ RUL_NasaEngineFinal.ipynb   # Full analysis & training notebook
â”œâ”€â”€ RUL_NasaEngineFinal.html    # Rendered HTML version of the notebook
â”œâ”€â”€ RUL_NasaEngineFinal.pdf     # PDF version of the notebook
â””â”€â”€ README.md
```

---

## ğŸ“¡ Dataset

**Source:** [NASA C-MAPSS Jet Engine Simulated Data](https://data.nasa.gov/dataset/cmapss-jet-engine-simulated-data)

The **Commercial Modular Aero-Propulsion System Simulation (C-MAPSS)** dataset was generated by NASA using a thermodynamic turbofan engine simulator. This project uses the **FD001** subset.

| Property | Value |
|---|---|
| Training engines | 100 units |
| Test engines | 100 units |
| Operating conditions | 1 |
| Fault modes | 1 (HPC degradation) |
| Sensors | 21 time-series measurements |
| Features used | 14 (after dropping constant/low-signal sensors) |

### Sensor Selection

After correlation analysis, the following low-information sensors were **dropped**:

`setting_1`, `setting_2`, `setting_3`, `s_1`, `s_5`, `s_6`, `s_10`, `s_14`, `s_16`, `s_18`, `s_19`

The **14 remaining sensors** (e.g. `s_2`, `s_3`, `s_4`, `s_7`, `s_11`, `s_12`) carry meaningful degradation signals and are used as model inputs.

### Target Variable â€” RUL

```
RUL = max_cycle - current_cycle   (clipped at 125 cycles)
```

Clipping at 125 cycles reflects the real-world assumption that early-life behaviour is stable and unpredictable; only the degradation phase is modelled.

---

## ğŸ—ï¸ Model Architecture

### Preprocessing Pipeline

```
Raw sensor data
      â”‚
      â–¼
Min-Max Normalization  â† fit on TRAIN only (no data leakage)
      â”‚
      â–¼
Sliding Window  â†’  sequences of shape (50 time steps Ã— 14 features)
      â”‚
      â–¼
LSTM Network
```

### LSTM Network

```
Input  â†’  (batch, 50 time steps, 14 features)
      â”‚
      â–¼  LSTM Layer 1 â€” 128 units, tanh, return_sequences=True
      â–¼  Batch Normalisation
      â–¼  Dropout (0.2)
      â”‚
      â–¼  LSTM Layer 2 â€” 64 units, tanh
      â–¼  Dropout (0.2)
      â”‚
      â–¼  Dense â€” 32 units, ReLU
      â–¼  Dense â€” 1 unit  (RUL regression output)
```

**Loss:** Mean Squared Error (MSE)  
**Optimizer:** Adam  
**Early Stopping:** patience = 10 epochs (monitors `val_loss`, restores best weights)

### Hyperparameter Tuning

An additional tuning pass was performed using **Keras Tuner (RandomSearch)** over:

| Hyperparameter | Search Range |
|---|---|
| LSTM units (layer 1) | 32 â†’ 128 (step 32) |
| LSTM units (layer 2) | 32 â†’ 64 (step 32) |
| Dropout rate | 0.1 â†’ 0.3 |
| Learning rate | 1e-4 â†’ 1e-2 |

The best configuration was re-trained for 50 epochs with the learning rate capped at `0.001` to avoid LSTM gradient instability.

---

## ğŸ“Š Results

| Metric | Baseline LSTM | Optimized LSTM |
|---|---|---|
| **RMSE** (cycles) | â€” | < 20 |
| **MAE** (cycles) | â€” | â€” |
| **NASA S-Score** | â€” | â€” |

> Exact values are printed at the end of `RUL_NasaEngineFinal.ipynb` after running all cells. Baseline metrics were not logged separately; the optimized model targets an RMSE below 20 cycles, which is considered **highly effective** for this benchmark.

**Evaluation plots generated by the notebook:**
- Training vs. Validation Loss (MSE & MAE)
- Actual RUL vs. Predicted RUL scatter plot
- Sensor degradation trend (per engine unit)

---

## ğŸ–¥ï¸ Live Dashboard

The Streamlit dashboard (`app.py`) lets you interactively inspect any engine unit from the test set.

**Features:**
- ğŸ›ï¸ Sidebar unit selector (Unit 1 â€“ 100)
- ğŸ”¢ Live RUL prediction metric (cycles remaining)
- ğŸ“‰ Pressure sensor (s_11) trend chart
- ğŸ› ï¸ Debugging panel showing data availability per unit

**Screenshot preview:**

> Run the app locally (see [Usage](#-usage)) and navigate to `http://localhost:8501`

---

## âš™ï¸ Installation

### Prerequisites

- Python 3.8 or higher
- `pip` package manager

### Steps

```bash
# 1. Clone the repository
git clone https://github.com/95karthik4/Turbofan-engine-predictive-maintenance-ai.git
cd Turbofan-engine-predictive-maintenance-ai

# 2. (Recommended) Create a virtual environment
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install tensorflow pandas numpy scikit-learn matplotlib seaborn streamlit keras-tuner
```

---

## ğŸš€ Usage

### Run the Interactive Dashboard

```bash
streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser. Use the sidebar to select an engine unit and see its predicted RUL and sensor trends instantly.

### Run the Full Notebook

```bash
jupyter notebook RUL_NasaEngineFinal.ipynb
```

Or view the pre-rendered versions:
- **HTML:** `RUL_NasaEngineFinal.html` â€” open in any browser
- **PDF:** `RUL_NasaEngineFinal.pdf`

### Retrain the Model

Execute all cells in `RUL_NasaEngineFinal.ipynb` from top to bottom. The notebook will:
1. Load and clean the data
2. Build and train the baseline LSTM
3. Run Keras Tuner hyperparameter search
4. Train the optimised model
5. Evaluate and save `nasa_rul_model.h5`

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|---|---|
| **Python 3.8+** | Core language |
| **TensorFlow / Keras** | LSTM model training & inference |
| **Keras Tuner** | Automated hyperparameter optimisation |
| **Pandas / NumPy** | Data manipulation |
| **Scikit-learn** | Min-Max scaling, evaluation metrics |
| **Matplotlib / Seaborn** | Visualisation |
| **Streamlit** | Interactive web dashboard |

---

## ğŸ‘¥ Team

**Group 5 â€” Capstone Project**

| Name | Role |
|---|---|
| Karthik Kunnamkumarath | Project Lead |
| Aswin Anil Bindu | Data Engineering & Modelling |
| Sreelakshmi Nair | Feature Engineering & Analysis |
| Tuna GÃ¼zelmeriÃ§ | Hyperparameter Tuning |
| Cindy Mai | Dashboard & Evaluation |

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

- **NASA** for the open-source [C-MAPSS dataset](https://data.nasa.gov/dataset/cmapss-jet-engine-simulated-data)
- The **PHM community** for benchmark methodologies and the NASA S-Score metric

---

<div align="center">
  <sub>Made with â¤ï¸ by Group 5</sub>
</div>
